{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance\n",
    "- Choosing to work with confidence intervals or statistical tests depends on degree of incorrectness you can tolerate.\n",
    "- Both are inferential techniques. 95% confidence level means that If you take repeated samples and compute the 95% confidence interval for a given parameter for each sample, 95% of the intervals would contain the population parameter.\n",
    "- Confidence Interval - used when estimating a population parameter eg mean, confidence level\n",
    "\n",
    "- In hypothesis testing, the significance level means something like this:\n",
    "\n",
    "Given that the null hypothesis is actually true, what probability will I tolerate of rejecting it anyway?\n",
    "\n",
    "This level is also known as the (alpha). You can think of it as what false positive rate will I tolerate.\n",
    "\n",
    "Some typical significance levels you might see are a 5% significance level or a 1% significance level. Setting a 5% significance level means that you would expect that 1 in 20 times, if you were performing this exact same experiment, you would reject the null hypothesis when it is actually true. Or for a 1% significance level, 1 in 100 times you would reject the null hypothesis when it is actually true.\n",
    "\n",
    "A statistically significant result means that the probability of obtaining that result, if the null hypothesis were true, is below the specified significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hypothesis- premise/claim.\n",
    "* Null hypothesis - default hypothesis- Ho->currently accepted value for a population.Based on past study.\n",
    "* Alternative hypothesis - Ha-research hypothesis->the claim to be tested. To be tested to challenge the null hypothesis\n",
    "* Ho and Ha are MATHEMATICALLY OPPOSITE, Ho : $\\mu$ = 5g, Ha : $\\mu$ != 5g\n",
    "\n",
    "## Possible Outcomes in Hypothesis:\n",
    "1. Reject the null hypothesis- not really saying the null hypothesis is true\n",
    "2. Fail to reject the null hypothesis - not really accepting that the alternative hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To determine whether to reject the null hypothesis or fail to reject the null hypothesis\n",
    "- Calculate the test statistic - 1. Get the sample_size eg 50 bars\n",
    "                                 2. Get avg value of the sample\n",
    "                                 3. Get the test statistic\n",
    "* STATISTICALLY SIGNIFICANT - where do we draw the line to make the decision\n",
    "if Avg = 7.5 g it's way more than 5g with statistically significant difference thus can reject the null hypothesis.\n",
    "\n",
    "* LEVEL OF CONFIDENCE - percentage of confidence causing the rejecting of the hypothesis\n",
    "\n",
    "* LEVEL OF SIGNIFICANCE - $\\alpha$ -> 1 - level of confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Designs \n",
    "- Steps :\n",
    " * 1. Identify an observation abt sth\n",
    " * 2. Check to see if similar experiments have been done before\n",
    "* 3. Form a hypothesis\n",
    "* 4. Conduct an experiment behind the hypothesis\n",
    "* 5. Analyze the results\n",
    "* 6. Draw conclusion - whether to reject null hypothesis or not reject \n",
    "\n",
    "## During the experiments do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sound experiment- experimenting done to determine the outcome of a hypothesis\n",
    "1. Controlled Group- group used to compare the effects of not doing sth eg. Drug trial, to test if a certain drug works to cure within less days.\n",
    "   - Select random samples from the same population, divide into groups, give one group the drug the other don't. We study both groups and see how\n",
    "       they behave contrary to each other\n",
    "2.  Random Controlled Trials - trials where there is a control group and an intervention (also called treatment) group, where subjects are randomly assigned to each. \n",
    " - In a sound experiment, people should not know if they are in the treatment group or the control group, as that could potentially affect the outcome of the trial!\n",
    "3. Single-Blind/Blind trial - is one where the participant does not know if they are receiving the treatment or a placebo(sugar pill)\n",
    "\n",
    "4. Double Blind - where the participant does not know if they are receiving the treatment or a placebo, and neither does the person administering the experiment (because their bias could affect the outcomes, too!). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Appropriate Sampling Techniques and Sample Size\n",
    " 1. Sample is independent- value of one observation does not influence or affect the value of other observations. If dependent, it can cause biasness.\n",
    " 2.  Sample is collected randomly - the selection of any individual observation happens by chance, rather than by choice.\n",
    "3. The sample is approximately normally distributed- The normal distribution assumption is that the sampling distribution of the mean is normal. That is, \n",
    "\n",
    "if you took a sample, calculated its mean, and then you took another (independent) sample (from the same population) and got its mean (and repeated this an infinite number of times), then the distribution of the values that you wrote down would always be a perfect bell curve. \n",
    "4. Appropriate Sample Size- Small sample sizes make experiments susceptible to the problem of randomness(luck); whereas, large sample sizes protect experiments \n",
    "\n",
    "from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reproducibility -\n",
    " - if someone else follows the series of steps used by you to perform the experiment by themselves, they should get the same results.\n",
    " - If many people try to follow your steps and don't get the same results, we might suggest that your results are due to randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance Level (α):\n",
    "\n",
    "   - The significance level is the threshold at which you decide whether to reject the null hypothesis.\n",
    "   - Commonly used significance levels are 0.05, 0.01, and 0.1.\n",
    "\n",
    "## p Value \n",
    "The p-value is the probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis is true.\n",
    "It quantifies the strength of the evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T tests\n",
    "1. One sample t test- to compare mean of a sample with a known mean eg if mean of chocolate bar is 50 gms, to 1 sample t test to get the avg mean \n",
    "of 50 bars, if the mean is 48gms, then the mean is significantly different from the claimed mean.\n",
    "\n",
    "- Null Hypothesis : sample mean = reference mean\n",
    "- Alternative Hypothesis : sample mean != reference mean\n",
    "\n",
    "2. Two sample t test/Independent sample t test- to compare means of two independent sample groups. To know if there is a significant difference between the means. Effectiveness of drug A compared to drug B\n",
    "- Null hypothesis : mean values of both groups are the same\n",
    "- Alternate hypothesis : mean values from both groups IS NOT the same\n",
    "\n",
    "3. Paired sample t test - compare means of two dependent groups. Getting the difference. Eg weigh people before dieting, then weigh after dieting then get the difference in their weights. To see if there is a significant difference.(pairs,repeated)\n",
    "- Null hypothesis : mean of the difference between the pairs is 0 \n",
    "- Alternate hypothesis : mean of the difference between the pairs IS NOT 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regardless of the type of t-test you are performing, there are 5 main steps to executing them:\n",
    "1. Set up null and alternative hypotheses\n",
    "\n",
    "2. Choose a significance level\n",
    "\n",
    "3. Calculate the test statistic (t-value)\n",
    "\n",
    "4. Determine the critical t-value (find the rejection region)\n",
    "\n",
    "5. Compare t-value with critical t-value to determine if we can reject the null hypothesis.\n",
    "\n",
    "Now, you're going to go through these 5 steps in more detail to complete a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use one tail test or two tail test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "in one tail test:\n",
    "    Null Hypothesis: H0: μ1 > μ2 - Right tail test (alpha is entire area of the right tail)\n",
    "    Alternative Hypothesis: Ha: μ1 < μ2 - Left  tail test (alpha is entire area of the left tail)\n",
    "\n",
    "    Null Hypothesis: H0: μ1 < μ2  - Left tail test \n",
    "    Alternative Hypothesis: Ha: μ1 > μ2 - Right tail test\n",
    "\n",
    "    Null Hypothesis: H0: μ1 <= μ2 - left tail test\n",
    "    Alternative Hypothesis: Ha: μ1 > μ2 - right tail test\n",
    "\n",
    "    Null Hypothesis: H0: μ1 >= μ2 - right tail test\n",
    "    Alternative Hypothesis: Ha: μ1 < μ2 - left tail test\n",
    "\n",
    "in two tail test:\n",
    "   Null Hypothesis: H0: μ1 = μ2 - Two tail test (alpha is entire area of the two tails, thus alpha/2 for each tail)\n",
    "    Alternative Hypothesis: Ha: μ1 ≠ μ2 - Two tail test\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0NE SAMPLE TEST \n",
    "- Used when population std is unknown and sample_size < 30 - determine whether single sample mean is significantly different from \n",
    "the population mean.\n",
    "### get the T VALUE \n",
    "t value = ($\\bar{x}$(sample_mean) - $\\mu$(population_mean))/(std/sqrt(n))(standard error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example - using the stat.ttest_1samp \n",
    "1. get population_mean, sample_mean, std, n, degree_of_freedom\n",
    "2. get t_statistic and p_value = stats.ttest_1samp(array,population_mean)\n",
    "3. compare p value and alpha value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "sample_heights = [162, 165, 167, 160, 170, 168, 159, 161, 164, 166, 163, 169, 158, 171, 162]\n",
    "\n",
    "# Known population mean\n",
    "population_mean = 165\n",
    "\n",
    "# Calculate sample statistics\n",
    "#get the sample mean, sample standard deviation, number of observations, and degrees of freedom\n",
    "sample_mean = np.mean(sample_heights)\n",
    "sample_std = np.std(sample_heights, ddof=1)\n",
    "n = len(sample_heights)\n",
    "df = n - 1\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_statistic, p_value = stats.ttest_1samp(sample_heights, population_mean)\n",
    "\n",
    "or\n",
    "\n",
    "t_statistic, p_value = stats.ttest_1samp(a=sample_heights, popmean=population_mean, alternative='two-sided')\n",
    "\n",
    "# Display the results\n",
    "print(f\"Sample mean: {sample_mean}\")\n",
    "print(f\"Sample standard deviation: {sample_std}\")\n",
    "print(f\"Degrees of freedom: {df}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Determine if we reject the null hypothesis\n",
    "alpha = 0.05 # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without using stats.ttest_1samp\n",
    "1. get population_mean, sample_mean, std of sample, n , degree_of freedom\n",
    "2. get t_statistic using the forumula = sample_mean - population_mean/(sample_std/sqrt(n))\n",
    "3. get t critical/tscore = stats.t.ppf(1- alpha/2, degree_of_freedom)\n",
    "4. margin_of_error = t_critical * (sample_std/np.sqrt(n))\n",
    "5. confidence_inteval = sample_mean -margin_of_error, sample_mean  + margin_of_error\n",
    "6. p value = 2 * (1- stats.t.cdf(abs(t_statistic)),df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "sample_heights = [162, 165, 167, 160, 170, 168, 159, 161, 164, 166, 163, 169, 158, 171, 162]\n",
    "\n",
    "# Known population mean\n",
    "population_mean = 165\n",
    "\n",
    "# Calculate sample statistics\n",
    "sample_mean = np.mean(sample_heights)\n",
    "sample_std = np.std(sample_heights, ddof=1)\n",
    "n = len(sample_heights)\n",
    "df = n - 1\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_statistic = (sample_mean - population_mean) / (sample_std / np.sqrt(n))\n",
    "\n",
    "# Find the critical t-value for a 95% confidence level (two-tailed test)\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "margin_of_error = t_critical * (sample_std / np.sqrt(n))\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df))\n",
    "\n",
    "# Display the results\n",
    "print(f\"Sample mean: {sample_mean}\")\n",
    "print(f\"Sample standard deviation: {sample_std}\")\n",
    "print(f\"Degrees of freedom: {df}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"Critical t-value: {t_critical}\")\n",
    "print(f\"95% confidence interval: {confidence_interval}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Determine if we reject the null hypothesis\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect size:\n",
    "- It tells us how big or small an effect is.\n",
    "- It allows comparison between different studies and their findings\n",
    "- Cohen's d: Used to measure the difference between two means in terms of standard deviation.\n",
    "\n",
    "    * Small effect: d≈0.2\n",
    "    * Medium effect: d≈0.5\n",
    "    * Large effect: d≈0.8d≈0.8 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = (np.mean(sample) - population_mean) / np.std(sample, ddof=1)\n",
    "\n",
    "# Interpretation of effect size\n",
    "if abs(effect_size) < 0.2:\n",
    "    print(\"The effect size is small.\")\n",
    "elif abs(effect_size) < 0.5:\n",
    "    print(\"The effect size is medium.\")\n",
    "else:\n",
    "    print(\"The effect size is large.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p VALUE\n",
    "- Probability of getting a data point more extreme on the left or right tails,than the data you collected for your hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type one and Type two error\n",
    "- Type 1 error = False positive. Man doing a pregnancy test and it comes back positive.\n",
    "    * Reject the null hypothesis when it is actually true\n",
    "    * P(Type 1 error) = $\\alpha$ \n",
    "- Type 2 error = False negative. Woman doing a pregnancy test and it comes back negative when she's actually pregnant.\n",
    "    * Failing to reject the null hypothesis when it is actually false.\n",
    "    * P(Type II error) = $\\beta$\n",
    "\n",
    "- P(Rejecting a false Null Hypothesis) = 1 - $\\beta$\n",
    "\n",
    "- When dealing with type 1 and 2 errors, identify the null hypothesis first, define type 1 and type 2 error then compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWO SAMPLE T TEST\n",
    "### get the value of t\n",
    "t value = ($\\mu$ s1 - $\\mu$ s2)/(sqrt((std**2 sample1/n s1) +( std**2 sample2/n s2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without using stat.ttest_ind\n",
    "-  if the variance of the samples are the same we use that the values are dependent and we use the Welch's t-test(randomness of taking values). THE VALUES ARE RELATED \n",
    "use bartlett() - test\n",
    "- if variance is not the same then there values are independent of each other.\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without using stat.ttest_ind\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "def two_sample_ttest(sample1, sample2, alpha=0.05, equal_var=True):\n",
    "    # Calculate sample statistics\n",
    "    mean1, mean2 = np.mean(sample1), np.mean(sample2)\n",
    "    var1, var2 = np.var(sample1, ddof=1), np.var(sample2, ddof=1) \n",
    "    n1, n2 = len(sample1), len(sample2)\n",
    "    \n",
    "    # Calculate the pooled standard deviation if variances are assumed equal\n",
    "    if equal_var:\n",
    "        pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
    "        se = np.sqrt(pooled_var * (1/n1 + 1/n2)) # this same as pooled_var / np.sqrt(n1 + n2)\n",
    "        df = n1 + n2 - 2\n",
    "    else:\n",
    "        # Calculate the standard error for unequal variances (Welch's t-test)\n",
    "        se = np.sqrt(var1/n1 + var2/n2)\n",
    "        df = ((var1/n1 + var2/n2) ** 2) / ((var1/n1) ** 2 / (n1 - 1) + (var2/n2) ** 2 / (n2 - 1))\n",
    "        \n",
    "    \n",
    "    # Calculate the t-statistic\n",
    "    t_stat = (mean1 - mean2) / se\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * stats.t.sf(np.abs(t_stat), df) # or 2 * (1 - stats.t.cdf(np.abs(t_stat), df))  ->stats.t.sf stands for survival function\n",
    "    \n",
    "    # Return the t-statistic, degrees of freedom, and p-value\n",
    "    return t_stat, df, p_value\n",
    "\n",
    "# Example usage\n",
    "sample1 = [84.0, 92.4, 74.3, 79.4, 86.7, 75.3, 80.9, 86.1, 81.0, 85.1]\n",
    "sample2 = [78.7, 73.5, 86.9, 87.4, 82.7, 81.9, 69.9, 77.2, 79.3, 83.3]\n",
    "\n",
    "t_stat, df, p_value = two_sample_ttest(sample1, sample2, equal_var=True)\n",
    "\n",
    "print(\"t_statistic:\", t_stat)\n",
    "print(\"degrees of freedom:\", df)\n",
    "print(\"p_value:\", p_value)\n",
    "\n",
    "# Check for significant difference\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The means of the two samples are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The means of the two samples are not significantly different.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using stat.ttest_ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the two samples\n",
    "sample1 = [84.0, 92.4, 74.3, 79.4, 86.7, 75.3, 90.9, 86.1, 81.0, 85.1]\n",
    "sample2 = [78.7, 73.5, 86.9, 87.4, 82.7, 81.9, 69.9, 77.2, 79.3, 83.3]\n",
    "\n",
    "# Perform the independent two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=True) # by default, it assumes equal variance\n",
    "#if not equal variance \n",
    "t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"t_statistic:\", t_stat)\n",
    "print(\"p_value:\", p_value)\n",
    "\n",
    "# Check for significant difference\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the two samples.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two samples.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired Sample t test\n",
    "1. difference = list( difference between the paired values)\n",
    "t value =  mean_of_difference - 0 /(std/sqrt(n))->(standard_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without using stat.ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def paired_ttest(sample1, sample2, alpha=0.05):\n",
    "    #1. Calculate the differences\n",
    "    differences = np.array(sample1) - np.array(sample2)\n",
    "    \n",
    "    #2.  Calculate mean and standard deviation of differences\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "\n",
    "    #3. calculate the t-statistic\n",
    "    n = len(differences)\n",
    "    t_statistic = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "    #4. Find the critical t-value\n",
    "    df = n - 1\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df) # used to calculate the margin of error which in turn is used to calculate the confidence interval\n",
    "    \n",
    "\n",
    "    #5. Calculate the p-value\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df))\n",
    "\n",
    "    # Return the t-statistic, degrees of freedom, and p-value\n",
    "    return t_stat, df, p_value\n",
    "\n",
    "# Example usage\n",
    "before_treatment = [84.0, 92.4, 74.3, 79.4, 86.7, 75.3, 90.9, 86.1, 81.0, 85.1]\n",
    "after_treatment = [78.7, 73.5, 86.9, 87.4, 82.7, 81.9, 69.9, 77.2, 79.3, 83.3]\n",
    "\n",
    "t_stat, df, p_value = paired_ttest(before_treatment, after_treatment)\n",
    "\n",
    "print(\"t_statistic:\", t_stat)\n",
    "print(\"degrees of freedom:\", df)\n",
    "print(\"p_value:\", p_value)\n",
    "\n",
    "# Check for significant difference\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the paired samples.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using stat.ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using stats.ttest_rel\n",
    "def paired_ttest(sample1, sample2, alpha=0.05):\n",
    "    #1. Calculate the differences\n",
    "    differences = np.array(sample1) - np.array(sample2)\n",
    "    \n",
    "    #2.  Calculate mean and standard deviation of differences\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "\n",
    "    #3. calculate the t-statistic\n",
    "    n = len(differences)\n",
    "    t_stat = mean_diff / (std_diff / np.sqrt(n))\n",
    "\n",
    "    #4. Perform a paired t-test\n",
    "    t_stat, p_value = stats.ttest_rel(sample1, sample2)\n",
    "      or \n",
    "    t_stat, p_value = stats.ttest_rel(a=after, b=before, alternative='two-sided')#a = after is the mean of the after treatment, b = before is the mean of the before treatment\n",
    "\n",
    "    # Return the t-statistic, degrees of freedom, and p-value\n",
    "    return t_stat, df, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using p value in normal distribution- Hypothesis testing in normal distribution\n",
    "1. state the null and alternate hypothesis\n",
    "2. specify the significance level $\\alpha$ = 0.05\n",
    "3. calculate the t -statistic/ zscore = ($\\bar{x}$- $\\mu$)/ ($\\sigma$/np.sqrt(n)). use the empirical rule (68,95,99) to understand z score\n",
    "- or use se = ($\\sigma$/np.sqrt(n))\n",
    "- t-stat = ($\\bar{x}$- $\\mu$)/se\n",
    "4. calculate the p value = p=> 1- stats.norm.cdf(zscore). We use cdf/pdf since it's normal distribution.\n",
    "5. use p value to choose whether to reject or fail to reject the null hypothesis.\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the ztest \n",
    "import numpy as np\n",
    "from scipy.stats.weightstats import ztest\n",
    "\n",
    "ztest(before_treatment, after_treatment, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect size\n",
    "difference between two groups(not samples.Use the groups to get the samples). difference between groups or the strength of a relationship between variables \n",
    "- Effect size serves three goals:\n",
    "1. Communicate practical significance of results.\n",
    "2. Meta Analytic calculations - group together a number of existing studies.\n",
    "3. Perform Power Anaysis - helps determine no of  people(sample size) a study requires to achieve a certain probability of finding a true effect-if there's one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## involves both standardized and unstandardized effect size\n",
    "- Unstandardized effect size - raw calculation of difference in means between two sample means\n",
    "  1. Used when the measurements are actually pretty important.\n",
    "  \n",
    "\n",
    "- Standardized effect size - use standadized methods for calculations\n",
    "- 1. COHEN'S d method\n",
    "    - Can be used when the standard deviation is not given. We assume that they follow a normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohen's d method\n",
    "#define a function that takes in two samples, calculates their means, length of the two samples, pooled variance and returns the cohen's d value\n",
    "def cohen_d(group1, group2):\n",
    "    #calculate the means of the groups\n",
    "    mean1 = group1.mean()\n",
    "    mean2 = group2.mean()\n",
    "\n",
    "    #calculate the lengths of the two groups\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    #get the variance of the two groups\n",
    "    group1_var = group1.var()\n",
    "    group2_var = group2.var()\n",
    "\n",
    "    #Calculate the pooled variance\n",
    "    pooled_variance = (n1 * group1_var + n2 *group2_var)/(n1+ n2) \n",
    "\n",
    "    #calculate the effect size\n",
    "    d = (mean1- mean2)/np.sqrt(pooled_variance) or (mean_after - mean_before) /std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of cohen's d\n",
    "small effect = 0.2\n",
    "medium effect = 0.5\n",
    "large effect = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the d you can get the overlap and superiority \n",
    "- 1. To get overlap and superiority \n",
    "\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_superiority(group1, group2, n=1000):\n",
    "    \"\"\"Estimates overlap and superiority based on a sample.\n",
    "    \n",
    "    group1: scipy.stats rv object\n",
    "    group2: scipy.stats rv object\n",
    "    n: sample size\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a sample of size n from both groups\n",
    "    group1_sample = group1.rvs(n)\n",
    "    group2_sample = group2.rvs(n)\n",
    "    \n",
    "    # Identify the threshold between samples\n",
    "    thresh = (group1.mean() + group2.mean()) / 2\n",
    "    print(thresh)\n",
    "    \n",
    "    # Calculate no. of values above and below for group 1 and group 2 respectively\n",
    "    above = sum(group1_sample < thresh)\n",
    "    below = sum(group2_sample > thresh)\n",
    "    \n",
    "    # Calculate the overlap\n",
    "    overlap = (above + below) / n\n",
    "    \n",
    "    # Calculate probability of superiority\n",
    "    superiority = sum(x > y for x, y in zip(group1_sample, group2_sample)) / n\n",
    "\n",
    "    return overlap, superiority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power- related to Type II error- false negative\n",
    "- Probability of correctly rejecting  a false null hypothesis./Probability of not making a type II error\n",
    "- Type II error - failing to reject the null hypothesis when it is actually false\n",
    "\n",
    "- power = 1- $\\beta$\n",
    "\n",
    "- Null Hypothesis (H₀): The hypothesis that there is no effect or no difference.\n",
    "- -Alternative Hypothesis (H₁): The hypothesis that there is an effect or a difference.\n",
    "- Type I Error (α): The probability of rejecting the null hypothesis when it is true (false positive).\n",
    "- Type II Error (β): The probability of failing to reject the null hypothesis when it is false (false negative).\n",
    "- Power (1 - β): The probability of correctly rejecting a false null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors affecting power\n",
    "1. Effect size( calculate use cohen's d)- The higher the effect the higher the power.\n",
    "2. significance level -  $\\alpha$ - the higher the significance level the higher the power\n",
    "3. sample size - Larger sample sizes provide more information and increase power.\n",
    "4. Variability - lower variability in data increases the power.\n",
    "5. One tailed test - has more power than a two tailed test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating power\n",
    "- You need:\n",
    "     1. Sample size(nobs)- no of observations, eg nobs = np.array(range(5,1500))\n",
    "     2. Effect size\n",
    "     3. significance level - alpha \n",
    "     4. df= degree of freedom n-1\n",
    "     Formula : statsmodels.stats.power.TTestPower.power\n",
    "      TTestPower.power(effect_size, nobs, alpha, df=None, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the sample size - using power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "#form normal distribution -> statsmodels.stats.power.NormalIndPower\n",
    "\n",
    "#define the power analysis object\n",
    "power_analysis = TTestIndPower() #if comparing two groups, independent T-test we use ratio \n",
    "\"\"\"\n",
    "Suppose you are designing a study to compare the means of two groups using an independent t-test.\n",
    " If you expect one group to have twice as many participants as the other, you would set ratio=2.0.\n",
    "\"\"\"\n",
    "\n",
    "#calculate the power\n",
    "power  = power_analysis.solve_power(effect_size=0.5, nobs1=100, alpha=0.5, ratio=1.0, alternative_='two-sided')\n",
    "\n",
    "print(power)\n",
    "\n",
    "\n",
    "#calculate the sample size\n",
    "sample_size = power_analysis.solve_power(effect_size=0.5, alpha=0.5,ratio=1.0, power=0.8, alternative='two-sided')\n",
    "\n",
    "#calculate the effect size\n",
    "effect_size = power_analysis.solve_power(nobs1=100, alpha=0.5, ratio=1.0, power=0.8, alternative='two-sided')\n",
    "\n",
    "##if unaware of the ratio between the two groups\n",
    "\"\"\"\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# Create power analysis object\n",
    "analysis = TTestIndPower()\n",
    "\n",
    "# Example: Exploring different ratios\n",
    "effect_size = 0.5  # Cohen's d effect size\n",
    "nobs1 = 100        # Sample size in group 1\n",
    "alpha = 0.05       # Significance level\n",
    "\n",
    "ratios_to_explore = [1.0, 1.5, 2.0, 3.0]  # List of ratios to explore\n",
    "\n",
    "for ratio in ratios_to_explore:\n",
    "    power = analysis.solve_power(effect_size=effect_size, nobs1=nobs1, alpha=alpha, ratio=ratio)\n",
    "    print(f\"Power with ratio {ratio}: {power}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B testing - Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use power analysis to calculate the sample size required to achieve a desired power level\n",
    "\n",
    "#formulate two groups mainly the control and treatment groups. For treatment group we use power formula to get the sample size required,\n",
    "#the power\n",
    "#Process:\n",
    "\"\"\"\"\n",
    "1. Define the effect size, alpha, and power - cohen d, alpha, power(1-beta)\n",
    "2. Create a power analysis object - eg power_analysis = TTestIndPower()\n",
    "3. Calculate the sample size - sample_size = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, ratio=1.0, alternative='two-sided')\n",
    "4. Print the sample size\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi square testing- Used for categorical testing, testing/comparing two categories\n",
    "- this test is used for making claims about the frequencies of categorical data. Because it is testing frequencies rather than population parameters, this test is known as a non-parametric test.\n",
    "- Here we represent data using bars not line graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a fair coin toss, the probability of getting a head is 0.5\n",
    "# the null hypothesis is that the coin is fair, and the alternative hypothesis is that the coin is biased\n",
    "# we will use a significance level of 0.05\n",
    "# we will perform a two-tailed test\n",
    "# we will use the binomial test to determine if the coin is biased\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Extract observed counts\n",
    "fair_coin_observed = coin_toss_counts.values\n",
    "# Heads and tails each expected half the time\n",
    "fair_coin_expected = [sum(coin_toss_counts)/2, sum(coin_toss_counts)/2]\n",
    "\n",
    "# Placeholder data for display purposes; you can ignore these values\n",
    "x = np.array([0, 5])\n",
    "offset = 1\n",
    "bar_width = 2\n",
    "\n",
    "# Plot bars\n",
    "ax.bar(x-offset, fair_coin_observed, bar_width, label=\"Observed\")\n",
    "ax.bar(x+offset, fair_coin_expected, bar_width, label=\"Expected\")\n",
    "\n",
    "# Customize appearance\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([\"Heads\", \"Tails\"])\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(loc=\"right\")\n",
    "fig.suptitle(\"Super Bowl Coin Tosses\");\n",
    "\n",
    "#perform a chi square test between observed and expected counts\n",
    "fair_coin_result = stats.chisquare(fair_coin_observed, fair_coin_expected)\n",
    "fair_coin_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA - Aanlysis of Variance Test\n",
    "- One way ANOVA - use it when  you have collected data about one categorical independent variable and one quantitative dependent variable. The independent variable should have at least three levels (i.e. at least three different groups or categories).\n",
    "\n",
    "         ANOVA tells you if the dependent variable changes according to the level of the independent variable. For example:\n",
    "\n",
    "       Your independent variable is social media use, and you assign groups to low, medium, and high levels of social media use to find out if there is a difference in hours of sleep per night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.3082146793126483\n",
      "p-value: 0.11873745490790563\n",
      "Fail to reject the null hypothesis: There is no significant difference between the groups.\n"
     ]
    }
   ],
   "source": [
    "#one way anova test\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the data\n",
    "group1 = [84.0, 92.4, 74.3, 79.4, 86.7, 75.3, 90.9, 86.1, 81.0, 85.1]\n",
    "group2 = [78.7, 73.5, 86.9, 87.4, 82.7, 81.9, 69.9, 77.2, 79.3, 83.3]\n",
    "group3 = [75.2, 80.1, 74.9, 77.2, 82.6, 79.2, 85.1, 78.3, 73.7, 80.6]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for significant difference\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2 way ANOVA test\n",
    "- An Analysis of Variance Test that has two independent variables is known as a Two-way ANOVA test. This test is also known as Factorial ANOVA Test.\n",
    "\n",
    "    For example, expanding the above example, a two-way ANOVA can examine the difference in the cases of Coronavirus (the dependent variable) by Age Group (the first independent variable) and Gender (the second independent variable). The two-way ANOVA can be utilized in order to examine the interaction among these two independent variables. Interactions denote that the differences are uneven across all classes of the independent v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two way anova test\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the data\n",
    "group1 = [84.0, 92.4, 74.3, 79.4, 86.7, 75.3, 90.9, 86.1, 81.0, 85.1]\n",
    "group2 = [78.7, 73.5, 86.9, 87.4, 82.7, 81.9, 69.9, 77.2, 79.3, 83.3]\n",
    "group3 = [75.2, 80.1, 74.9, 77.2, 82.6, 79.2, 85.1, 78.3, 73.7, 80.6]\n",
    "factor1 = [\"A\"] * len(group1) + [\"B\"] * len(group2) + [\"C\"] * len(group3)\n",
    "factor2 = [\"X\", \"Y\"] * 15\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3, factor1, factor2)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
