{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to improve model performance\n",
    "1. Data. Get better data, more data\n",
    "2. Engineer certain features.\n",
    "3. Clean up data. Remove rows to reduce multicollinearity \n",
    "4. Parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "- Ways to \n",
    "1. GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using GridSearchCV to find the best parameters for the DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "#split the data into features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "#split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#create the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid ={\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "\n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "#clf is the model,param_grid is the parameters, cv is the number of folds, scoring is the metric to use\n",
    "grid_search = GridSearchCV(clf, param_grid, cv= 5 , scoring='accuracy')\n",
    "#fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "#find the best parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV  for LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "#split the data into features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "#split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#create the LogisticRegression\n",
    "clf = LogisticRegression( max_iter=1000)#max_iter is the maximum number of iterations taken for the solvers to converge to avoid convergence warning\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid ={\n",
    "    'penalty': ['l1', 'l2'],# l1 is Lasso, l2 is Ridge. Lasso penalizes the coefficients to zero when column not needed, Ridge does not penalize the coefficients to zero but reduces the size of the coefficients of the columns that are not needed\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], #C is the inverse of the regularization strength, smaller values specify stronger regularization\n",
    "    'solver':['liblinear', 'lbfgs']#solver is the algorithm to use in the optimization problem\n",
    "\n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(clf,param_grid,cv=5, scoring='accuracy')\n",
    "#fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "#find the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "- Ways of implementing more than one method.\n",
    "eg implementing the StandardScaler and LogisticRegression model \n",
    "-  we want to clean our data, transform it, potentially use feature selection, and then run a machine learning algorithm. Using pipelines, you can do all these steps in one go!\n",
    "- Very useful if you want to deploy your model.It's easier to change the pipeline than the codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid= {\n",
    "    'clf__criterion': ['gini', 'entropy'], #criteria to split the data either gini or entropy.\n",
    "    'clf__max_depth': [1, 2, 5, 10],# maximum depth of the tree. \n",
    "    'clf__min_samples_split': [2, 5, 10], #minimum number of samples required to split an internal node\n",
    "    'clf__min_samples_leaf': [1, 2, 5, 10], #minimum number of samples required to be at a leaf node\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "#or\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "grid = ([\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], #inverse of the regularization strength the smaller the value the stronger the regularization\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "#Get the test score\n",
    "print(grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods\n",
    "- Machine learning Algorithms\n",
    "- **Ensemble:** to an algorithm that makes use of more than one model to make a prediction. \n",
    "- Models used in ensembles.\n",
    "1. Random Forest :  an ensemble method for decision trees that takes advantage of bagging and the subspace sampling method to create a \"forest\" of decision trees that provides consistently better predictions than any single decision tree.\n",
    "2. Gradient Boosted Trees.\n",
    "-Ensemble methods are powerful techniques in machine learning that combine multiple models to produce a more robust and accurate prediction than any single model could achieve on its own. The core idea is that by aggregating the predictions of several models, the ensemble can reduce variance, bias, or improve the overall predictive performance.\n",
    "\n",
    "**Key Concepts of Ensemble Methods:**\n",
    "\n",
    "   1.  Diversity of Models: Ensemble methods rely on the principle that different models may capture different patterns in the data. By combining these models, the ensemble can mitigate the weaknesses of individual models.\n",
    "\n",
    "    2. Aggregation: The outputs of the individual models are combined using methods like voting, averaging, or stacking, to produce the final prediction.\n",
    "\n",
    "**Types of Ensemble Methods:**\n",
    "\n",
    " 1. **Bagging(Bootstrap Aggregating):**\n",
    "        How It Works: Bagging involves training multiple models on different random subsets (with replacement) of the original training data. Each model is trained independently, and the final prediction is made by averaging the predictions (for regression) or by majority voting (for classification).\n",
    "\n",
    "- Example: Random Forest is a popular bagging method where multiple decision trees are trained, and their predictions are aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Boosting** - Boosting trains models sequentially, where each new model tries to correct the errors made by the previous ones. The models are combined to form a strong learner, with each model focusing on the mistakes made by its predecessors.\n",
    "- Gradient Boosting Machines (GBM), AdaBoost, XGBoost, and LightGBM are popular boosting algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Stacking** - Stacking involves training multiple models (often different types of models) and then using another model (meta-learner) to combine the predictions of these base models. The meta-learner is trained on the predictions of the base models as input features.\n",
    "- You might use a logistic regression model as a meta-learner to combine the outputs of a decision tree, a random forest, and a support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('svc', SVC(probability=True))\n",
    "]\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **VotingClassifier** - A voting classifier is an ensemble that combines several different models and predicts the class label based on the majority vote (for classification) or the average prediction (for regression). The models can be of different types.\n",
    "\n",
    "- Example: Combining a decision tree, a logistic regression, and a k-nearest neighbors (KNN) classifier into a voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', model1),\n",
    "    ('knn', model2),\n",
    "    ('dt', model3)\n",
    "], voting='hard')  # 'hard' for majority vote, 'soft' for weighted probabilities\n",
    "voting_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## difference between Boosting and Bagging\n",
    "- Bagging(Random Forest) Boosting(Gradient Boosting)\n",
    "1. **Independent vs Iterative :** In bagging random forest trains each tree independently and at the same time.\n",
    "- Boosting trains each tree iteratively.\n",
    "-  In a random forest model, how well or poorly a given tree does has no effect on any of the other trees since they are all trained at the same time. Boosting, on the other hand, trains trees one at a time, identifies the weak points for those trees, and then purposefully creates the next round of trees in such a way as to specialize in those weak points.\n",
    "2. **Weak vs Strong:** In a random forest, each tree is a strong learner -- they would do just fine as a decision tree on their own. In boosting algorithms, trees are artificially limited to a very shallow depth (usually only 1 split), to ensure that each model is only slightly better than random chance.\n",
    "3. **Aggregate Predictions:** In random forest, each tree votes for the final result while boosting algorithm employs a system of weights to determine how important the input for each tree is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Algorithm and Gradient Boosted Trees\n",
    "- **Adaptive Boosting Algorithm:** combines the predictions of several weak learners to create a strong learner. The idea behind AdaBoost is to improve the accuracy of any machine learning algorithm by focusing on the instances that are hardest to classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboostClassifier and GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "#adaBoostClassifier\n",
    "ada = AdaBoostClassifier(random_state=42,)\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid ={\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "      \n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(ada, param_grid,cv=5, scoring='accuracy')\n",
    "#fit the model\n",
    "grid_search.fit(X, y)\n",
    "#find the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "#to get the classification report\n",
    "ada_test_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, ada_test_pred))\n",
    "\n",
    "#to get the confusion matrix\n",
    "print(confusion_matrix(y_test, ada_test_pred))\n",
    "\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid={\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'subsample': [0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#fit the model \n",
    "grid_search.fit(X,y)\n",
    "\n",
    "#find the best parameters\n",
    "print(grid_search.best_params_)\n",
    "#to get the classification report\n",
    "gbc_test_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, gbc_test_pred))\n",
    "\n",
    "#to get the confusion matrix\n",
    "print(confusion_matrix(y_test, gbc_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top best GradientBoostingClassifier is XBoost(eXtreme Gradient Boosting.)\n",
    "- When using the XBoost the y variable needs to be label encoded from 0 going foward.\n",
    "- So instantiate the LabelEncoder\n",
    "- fit_transform the y_train \n",
    "- transform the y_test \n",
    "\n",
    "- Use the transformed y_train and y_test to get the predicted values and calculate the accuracy. Even when using the GridSearchCV for parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#instantiate the model\n",
    "clf = XGBClassifier()\n",
    "\n",
    "#label encode the target\n",
    "encoder = LabelEncoder()\n",
    "fitted_y_train = encoder.fit_transform(y_train)\n",
    "fitted_y_test = encoder.transform(y_test)\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'n_estimators': [100],\n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "#fit \n",
    "grid_search.fit(X_train, fitted_y_train)\n",
    "#find the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "#to get the classification report\n",
    "xgb_test_pred = grid_search.predict(X_test)\n",
    "print(classification_report(fitted_y_test, xgb_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use Ensemble methods\n",
    "1. complex datasets with many features or non-linear relationships.\n",
    "2. Methods like bagging (e.g., Random Forest) can help reduce overfitting by averaging out the variance from different models.\n",
    "3.  Boosting techniques reduce bias by sequentially focusing on hard-to-predict samples, while bagging methods reduce variance by averaging across multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages\n",
    "1. Improved Accuracy: Ensembles typically perform better than single models.\n",
    "2. Robustness: Less likely to be affected by outliers or noise in the data.\n",
    "3. Versatility: Can be applied to various types of models and problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disadvantages\n",
    "1. Complexity: Ensembles are more complex to understand and interpret than individual models.\n",
    "2. Computationally Intensive: Training multiple models can require more computational resources and time.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- Used to apply/ fit parameters for it to choose the best parameters to train with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing the GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#initialize the model\n",
    "clf = RandomForestClassifier(random_state=42,)\n",
    "\n",
    "#set the parameters to search\n",
    "param_grid = {\n",
    "    'n_estimators':[100,200,300,400],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth': [1,2,5,10],\n",
    "    'min_samples_split':[None, 2, 5, 10],\n",
    "    'min_samples_leaf':[1,2,5,10],\n",
    "}\n",
    "\n",
    "#use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(clf,param_grid, cv=5, scoring= 'accuracy')\n",
    "\n",
    "#fit the model \n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#To find the best parameters. These are all the parameters needed to get the best score\n",
    "grid_search.best_params_\n",
    "# to find the best score. This score is the mean cross-validated score of the best_estimator\n",
    "grid_search.best_score_\n",
    "# to find the best estimator. The best estimator is the number of trees that give the best score.\n",
    "grid_search.best_estimator_\n",
    "\n",
    "\"\"\"to find the mean cross validation score of the best estimator\n",
    "to understand the model's expected performance based on cross- validation \n",
    "\"\"\"\n",
    "grid_search.cv_results_['mean_train_score'][grid_search.best_index_]#mean_train_score will give an array of the mean training score of the best index\n",
    "#thus to get a  value we use the index of the best index\n",
    "\"\"\"\n",
    "to find the test score of the best estimator\n",
    "to find out how the model performs on unseen data\n",
    "\"\"\"\n",
    "grid_search.score(X_test, y_test)  or  grid_search.best_estimator_.score(X_test,y_test)\n",
    "#or \n",
    "#to find the mean cross validation score of the best estimator\n",
    "grid_search.cv_results_['mean_test_score'][grid_search.best_index_]#mean_test_score will give an array of the mean test score of the best index\n",
    "\n",
    "\"\"\"\n",
    "The results from the test score is the accuracy score for classification and R2 score for regression.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Between the Models:\n",
    "\n",
    " 1. **Problem Complexity:**\n",
    "        Random Forest is a strong baseline for many problems. If you need a fast, reliable classifier with minimal tuning, Random Forest is a good choice.\n",
    "        Gradient Boosting (especially with libraries like XGBoost, LightGBM, or CatBoost) can achieve higher performance on more complex tasks but at the cost of more tuning and slower training.\n",
    "        AdaBoost can be useful when you have simple models or weak learners and want to boost their performance without excessive complexity.\n",
    "\n",
    "    2. **Speed and Size of Dataset:**\n",
    "        Random Forest can be faster to train and test on larger datasets.\n",
    "        Gradient Boosting is typically slower but can achieve better results on complex datasets.\n",
    "        AdaBoost is lightweight and can be faster than Gradient Boosting but may not perform as well on complex tasks.\n",
    "\n",
    "    3. **Model Tuning:**\n",
    "        Random Forest requires minimal tuning (number of trees, max depth).\n",
    "        Gradient Boosting can require extensive hyperparameter tuning (learning rate, number of estimators, max depth, etc.) for optimal results.\n",
    "        AdaBoost has fewer hyperparameters to tune but can still benefit from parameter adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-It is good practice to instantiate all the three ensemble models and use cross_val_score to see which one has a higher score. Pick the model with the highest mean cross_val_score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
